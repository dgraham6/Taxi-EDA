{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6fce5369-fe7f-4e5f-93f4-00f74183d278",
   "metadata": {},
   "source": [
    "# Taxi Trip Exploratory Data Analysis\n",
    "\n",
    "**Name(s)**: Drake Graham\n",
    "\n",
    "**Website Link**: https://dgraham6.github.io/Taxi-EDA/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93b3a57e-1cfc-4a30-8669-9b1f1e3aff98",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'plotly'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mplotly\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexpress\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpx\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrequests\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'plotly'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "import folium\n",
    "from folium.plugins import MarkerCluster\n",
    "import googlemaps\n",
    "import time\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer, StandardScaler, OneHotEncoder, PolynomialFeatures\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.compose import make_column_transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cae6a9e-4b7b-4fff-b136-d6f33f33d4bb",
   "metadata": {},
   "source": [
    "## Step 1: Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e4c9166-7e30-42af-bffb-266ce538447c",
   "metadata": {},
   "source": [
    "Here are some initial questions about the dataset:  \n",
    "- On what days do taxi drivers generate the most revenue?  \n",
    "- What is the relationship between trip characteristics, such as distance and duration, and revenue?  \n",
    "- Are there significant differences in performance between taxi companies?  \n",
    "\n",
    "After consideration, I decided to focus on a what I think is the most important: predicting how long a trip will last. This has practical applications in improving route efficiency, setting accurate expectations for customers, and optimizing fleet management for taxi companies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b3b2d89-f16c-4167-85a4-f2ec23d2790a",
   "metadata": {},
   "source": [
    "## Step 2: Data Cleaning and Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c0ea17e-1862-46ca-bfaa-21169365bfe8",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m taxi \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcurve.csv\u001b[39m\u001b[38;5;124m'\u001b[39m,low_memory\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "taxi = pd.read_csv('curve.csv',low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77fbe2cb-5af9-47b1-9b6e-38521f5e2eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "durations = pd.read_csv('durations.csv', low_memory=False)\n",
    "taxi = pd.read_csv('OpenDataDC_Taxi_2024/taxi_2024_10.csv')\n",
    "for i in range(1, 9):\n",
    "    taxi = pd.concat([taxi, pd.read_csv(f\"OpenDataDC_Taxi_2024/taxi_2024_0{i}.csv\")], axis=0)\n",
    "for i in range(0,2):\n",
    "    taxi = pd.concat([taxi, pd.read_csv(f\"OpenDataDC_Taxi_2024/taxi_2024_1{i}.csv\")], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab8ca00-34b7-4e5e-b996-c3338705d457",
   "metadata": {},
   "outputs": [],
   "source": [
    "osrm_url = \"http://localhost:8080/route/v1/driving\"\n",
    "\n",
    "\n",
    "def batch_coordinates(df, batch_size):\n",
    "    for i in range(0, len(df), batch_size):\n",
    "       yield df.iloc[i:i + batch_size]\n",
    "\n",
    "def format_coordinates(row):\n",
    "    return f\"{row['ORIGIN_BLOCK_LONGITUDE']},{row['ORIGIN_BLOCK_LATITUDE']};{row['DESTINATION_BLOCK_LONG']},{row['DESTINATION_BLOCK_LAT']}\"\n",
    "\n",
    "\n",
    "def get_route_duration_distance(coords):\n",
    "    try:\n",
    "        response = requests.get(f\"{osrm_url}/{coords}?overview=false\")\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            if 'routes' in data and len(data['routes']) > 0:\n",
    "                route = data['routes'][0]\n",
    "                return route.get('duration', None), route.get('distance', None)\n",
    "            else:\n",
    "                return None, None\n",
    "        else:\n",
    "            return None, None\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return None, None\n",
    "\n",
    "\n",
    "durations, distances = [], []\n",
    "for batch in tqdm(batch_coordinates(taxi, batch_size=50), total=len(taxi) // 50 + 1):\n",
    "    for _, row in batch.iterrows():\n",
    "        coords = format_coordinates(row)\n",
    "        duration, distance = get_route_duration_distance(coords)\n",
    "        durations.append(duration)\n",
    "        distances.append(distance)\n",
    "        \n",
    "taxi['duration'] = durations\n",
    "taxi['distance'] = distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77353b1-a93b-4483-82e7-d74f9a6f557c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openmeteo_requests\n",
    "import requests_cache\n",
    "import pandas as pd\n",
    "from retry_requests import retry\n",
    "\n",
    "cache_session = requests_cache.CachedSession('.cache', expire_after=-1)\n",
    "retry_session = retry(cache_session, retries=5, backoff_factor=0.2)\n",
    "openmeteo = openmeteo_requests.Client(session=retry_session)\n",
    "\n",
    "\n",
    "url = \"https://archive-api.open-meteo.com/v1/archive\"\n",
    "params = {\n",
    "    \"latitude\": 38.9072, \n",
    "    \"longitude\": -77.0369,  \n",
    "    \"start_date\": \"2024-01-01\", \n",
    "    \"end_date\": \"2024-11-01\",  \n",
    "    \"hourly\": \"snowfall,precipitation\"  \n",
    "}\n",
    "\n",
    "\n",
    "responses = openmeteo.weather_api(url, params=params)\n",
    "response = responses[0]  \n",
    "\n",
    "hourly = response.Hourly()\n",
    "hourly_snowfall = hourly.Variables(0).ValuesAsNumpy()  \n",
    "hourly_precipitation = hourly.Variables(1).ValuesAsNumpy()\n",
    "\n",
    "\n",
    "weather_data = {\n",
    "    \"time\": pd.date_range(\n",
    "        start=pd.to_datetime(hourly.Time(), unit=\"s\", utc=True),\n",
    "        end=pd.to_datetime(hourly.TimeEnd(), unit=\"s\", utc=True),\n",
    "        freq=pd.Timedelta(seconds=hourly.Interval()),\n",
    "        inclusive=\"left\"\n",
    "    ),\n",
    "    \"snowfall\": hourly_snowfall,\n",
    "    \"precipitation\": hourly_precipitation\n",
    "}\n",
    "weather_df = pd.DataFrame(weather_data)\n",
    "\n",
    "weather_df[\"time\"] = pd.to_datetime(weather_df[\"time\"], utc=True)\n",
    "taxi[\"time\"] = pd.to_datetime(taxi[\"Time\"], utc=True)\n",
    "\n",
    "\n",
    "taxi = pd.merge(taxi, weather_df, on=\"time\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb851930-246f-4721-8eef-fb7d3b23e0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi['Hour of Day'] = taxi['ORIGINDATETIME_TR'].dt.hour\n",
    "\n",
    "grouped = taxi.groupby(['Day of the Week', 'Hour of Day']).agg(\n",
    "    total_mileage=('MILEAGE', 'sum'),\n",
    "    avg_duration=('DURATION', 'mean'),\n",
    "    avg_temp=('temp', 'mean')\n",
    ").reset_index()\n",
    "\n",
    "pivot_table = grouped.pivot_table(\n",
    "    index=['Day of the Week'],\n",
    "    columns='Hour of Day',\n",
    "    values=['total_mileage', 'avg_duration', 'avg_temp'],\n",
    "    aggfunc='mean'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e63748-3d02-4171-a8fe-8a87b9f45626",
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi = taxi.drop(taxi.loc[(taxi['DURATION'] < 1) | (taxi['DURATION'] > 3600)].index)\n",
    "taxi = taxi.drop(taxi.loc[(taxi['distance'] < 10) & (taxi['MILEAGE'] < 0.1)].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c45aa9e2-e13d-4c4d-a6da-258821473f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(taxi, x='snowfall', y='Duration(m)',\n",
    "                         title='Heatmap of Weather Metric vs Trip Duration',\n",
    "                         labels={'severerisk': 'Weather Metric', 'DURATION': 'Trip Duration (minutes)'},\n",
    "                         )\n",
    "fig.update_yaxes(title_text='Trip Duration(m)', range=[30, 50])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f55cb96-a993-4176-b2bc-67b6af231d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi['Time']  = pd.to_datetime(taxi['ORIGINDATETIME_TR'], format='%m/%d/%Y %H:%M')\n",
    "taxi['Duration(m)'] = taxi['DURATION'] / 60\n",
    "taxi['Time'] = pd.to_datetime(taxi['Time'])\n",
    "taxi['Day of the Week'] = taxi['Time'].dt.day_name()\n",
    "taxi = pd.get_dummies(taxi, columns=['Day of the Week'])\n",
    "week = taxi.groupby('Day of the Week', as_index=False)['Duration(m)'].count()\n",
    "day_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "week['Day of the Week'] = pd.Categorical(week['Day of the Week'], categories=day_order, ordered=True)\n",
    "week = week.sort_values('Day of the Week')\n",
    "taxi['Day of the Week'] = week['Day of the Week']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99325888-e79f-426a-b0fd-e10dcb7d0b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_center(X):\n",
    "    return X.assign(\n",
    "        CenterLat=(X[\"ORIGIN_BLOCK_LATITUDE\"] + X[\"DESTINATION_BLOCK_LAT\"]) / 2,\n",
    "        CenterLong=(X[\"ORIGIN_BLOCK_LONGITUDE\"] + X[\"DESTINATION_BLOCK_LONG\"]) / 2\n",
    "    )\n",
    "def compute_direction(X):\n",
    "    return X.assign(\n",
    "        Direction=X.apply(\n",
    "            lambda row: (\n",
    "                'NorthEast' if row['DESTINATION_BLOCK_LAT'] > row['ORIGIN_BLOCK_LATITUDE'] and row['DESTINATION_BLOCK_LONG'] > row['ORIGIN_BLOCK_LONGITUDE'] else\n",
    "                'NorthWest' if row['DESTINATION_BLOCK_LAT'] > row['ORIGIN_BLOCK_LATITUDE'] and row['DESTINATION_BLOCK_LONG'] < row['ORIGIN_BLOCK_LONGITUDE'] else\n",
    "                'SouthEast' if row['DESTINATION_BLOCK_LAT'] <= row['ORIGIN_BLOCK_LATITUDE'] and row['DESTINATION_BLOCK_LONG'] >= row['ORIGIN_BLOCK_LONGITUDE'] else\n",
    "                'SouthWest'\n",
    "            ),\n",
    "            axis=1\n",
    "        )\n",
    "    )\n",
    "def haversine(lat1, lon1, lat2, lon2):\n",
    "    R = 3959\n",
    "    lat1, lon1, lat2, lon2 = map(np.radians, [lat1, lon1, lat2, lon2])\n",
    "    dlat = lat2 - lat1\n",
    "    dlon = lon2 - lon1\n",
    "    a = np.sin(dlat / 2.0) ** 2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon / 2.0) ** 2\n",
    "    c = 2 * np.arctan2(np.sqrt(a), np.sqrt(1 - a))\n",
    "    return R * c\n",
    "    \n",
    "def compute_distance(X):\n",
    "    return X.assign(\n",
    "        Distance=(haversine(X[\"ORIGIN_BLOCK_LATITUDE\"], X[\"ORIGIN_BLOCK_LONGITUDE\"],X[\"DESTINATION_BLOCK_LAT\"], X[\"DESTINATION_BLOCK_LONG\"]))\n",
    "    )\n",
    "    \n",
    "busy_roads = []\n",
    "def check_roads(x):\n",
    "    for road in x:\n",
    "        if road in busy_roads:\n",
    "            return 1\n",
    "    return 0\n",
    "\n",
    "def compute_traffic(X):\n",
    "    return X.assign(\n",
    "        Traffic=(check_roads(X['roads']))\n",
    "    )\n",
    "\n",
    "def final_model(X_train, y_train):\n",
    "    rmsle_scorer = make_scorer(rmsle, greater_is_better=False)\n",
    "\n",
    "    add_traffic = FunctionTransformer(compute_traffic)\n",
    "    add_center = FunctionTransformer(compute_center)\n",
    "    add_direction = FunctionTransformer(compute_direction)\n",
    "    add_distance = FunctionTransformer(compute_distance)\n",
    "\n",
    "    num_features = X_train.select_dtypes(include=[\"number\"]).columns\n",
    "    cat_features = X_train.select_dtypes(include=[\"object\"]).columns\n",
    "\n",
    "    num_preprocessor = Pipeline([\n",
    "        (\"imputer\", SimpleImputer(strategy=\"mean\")),\n",
    "        (\"poly_features\", PolynomialFeatures(degree=2, include_bias=False)),\n",
    "        (\"scaler\", StandardScaler())\n",
    "    ])\n",
    "    cat_preprocessor = Pipeline([\n",
    "        (\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=\"Unknown\")),\n",
    "        (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "    ])\n",
    "\n",
    "    column_transformer = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"num\", num_preprocessor, num_features), \n",
    "            (\"cat\", cat_preprocessor, cat_features)   \n",
    "        ],\n",
    "        remainder=\"drop\"\n",
    "    )\n",
    "\n",
    "    pipeline = Pipeline([\n",
    "        (\"add_traffic\", add_traffic),\n",
    "        (\"add_distance\", add_distance),\n",
    "        (\"add_center\", add_center),\n",
    "        (\"add_direction\", add_direction),\n",
    "        (\"preprocessor\", column_transformer),\n",
    "        (\"regressor\", LinearRegression())\n",
    "    ])\n",
    "\n",
    "    hyperparams = {\n",
    "        \"preprocessor__num__poly_features__degree\": [2]  # Tune degree for polynomial features\n",
    "    }\n",
    "\n",
    "    searcher = GridSearchCV(\n",
    "        pipeline,\n",
    "        param_grid=hyperparams,\n",
    "        cv=5,\n",
    "        scoring=rmsle_scorer,\n",
    "    )\n",
    "\n",
    "    searcher.fit(X_train, y_train)\n",
    "    return searcher\n",
    "    \n",
    "pipe_final = final_model(X_train, y_train)\n",
    "y_test_pred = pipe_final.predict(X_test)\n",
    "rmsle_score = rmsle(y_test, y_test_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
